{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC (b): aggregate over shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy request_api and mask function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "import time\n",
    "\n",
    "# a wrapper function to request ERA5 API\n",
    "# f_name: the name of the file to be requested\n",
    "# shape: the ARBITRARY shape of the area to be requested\n",
    "#        if None, the whole world will be queried\n",
    "#        otherwise, the request ERA5 API with the bounding box of the shape\n",
    "# return: the path of the file downloaded\n",
    "def request_era5_api(f_name, shape=None):\n",
    "    fpath = f'data/download/{f_name}'\n",
    "    if shape is None:\n",
    "        area = [90, -180, -90, 180]\n",
    "    else:\n",
    "        west, sorth, east, north = shape.bounds\n",
    "        area = [north, west, sorth, east]\n",
    "\n",
    "    print('\\n### ~~~~~~ ###')\n",
    "    print('START requesting ERA5 API')\n",
    "    start = time.time()\n",
    "\n",
    "    c = cdsapi.Client()\n",
    "    c.retrieve('reanalysis-era5-single-levels', {\n",
    "        'product_type': 'reanalysis',\n",
    "        'format': 'netcdf',\n",
    "        'variable': '2m_temperature',\n",
    "        'year': '2023',\n",
    "        'month': '01',\n",
    "        'day': '05',\n",
    "        'time': [\n",
    "            '00:00',\n",
    "            '01:00',\n",
    "            '02:00',\n",
    "            '03:00',\n",
    "            '04:00',\n",
    "            '05:00',\n",
    "            '06:00',\n",
    "            '07:00',\n",
    "            '08:00',\n",
    "            '09:00',\n",
    "            '10:00',\n",
    "            '11:00',\n",
    "            '12:00',\n",
    "            '13:00',\n",
    "            '14:00',\n",
    "            '15:00',\n",
    "            '16:00',\n",
    "            '17:00',\n",
    "            '18:00',\n",
    "            '19:00',\n",
    "            '20:00',\n",
    "            '21:00',\n",
    "            '22:00',\n",
    "            '23:00',\n",
    "        ],\n",
    "        'area': area,\n",
    "    }, fpath)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f'DONE requesting ERA5 API in {end - start} seconds')\n",
    "    print('### ~~~~~~ ###\\n')\n",
    "\n",
    "    return fpath\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import folium\n",
    "import time\n",
    "\n",
    "# a function to mask the raster data with arbitrary shape\n",
    "# fpath: the path of the raster data\n",
    "# shape: the ARBITRARY shape\n",
    "# return: the mask of the raster data, which is a boolean 2-D array\n",
    "def shape_mask(fpath, shape):\n",
    "    print('\\n### ~~~~~~ ###')\n",
    "    print('START masking raster data with arbitrary shape')\n",
    "    start = time.time()\n",
    "\n",
    "    gdf_shape = gpd.GeoDataFrame(geometry=[shape], crs=4326)\n",
    "\n",
    "    ds = xr.open_dataset(fpath)\n",
    "    print(f'shape of the whole raster data: {ds[\"t2m\"].shape}')\n",
    "    ds_2d = ds.isel(time=0)  # using a 2-D slice of the raster to construct the geospatail content of the pixels\n",
    "    print(f'shape of the sliced raster data: {ds_2d[\"t2m\"].shape}')\n",
    "\n",
    "    # take a record of the lat/lon location in the raster data\n",
    "    df_lat = pd.DataFrame(enumerate(ds_2d['latitude'].values), columns=['lat_index', 'latitude'])\n",
    "    df_lon = pd.DataFrame(enumerate(ds_2d['longitude'].values), columns=['lon_index', 'longitude'])\n",
    "\n",
    "    df_2d = ds_2d.to_dataframe()\n",
    "    df_2d = df_2d.reset_index()\n",
    "    df_2d = df_2d[['latitude', 'longitude', 't2m']]\n",
    "    df_2d = df_2d.merge(df_lat, on='latitude')\n",
    "    df_2d = df_2d.merge(df_lon, on='longitude')\n",
    "    gdf_2d = gpd.GeoDataFrame(\n",
    "        df_2d,\n",
    "        geometry=gpd.points_from_xy(df_2d.longitude, df_2d.latitude),\n",
    "        crs=4326,\n",
    "    )  # construct the geospatail dataframe of the pixels\n",
    "    gdf_masked = gdf_2d.sjoin(gdf_shape, how='inner', predicate=\"within\")  # join the pixels with the shape, use GeoPandas spatial join\n",
    "\n",
    "    # construct the mask of based on the lat/lon location of the pixels within the shape\n",
    "    lat_index = gdf_masked['lat_index'].values\n",
    "    lon_index = gdf_masked['lon_index'].values\n",
    "    mask = np.zeros(ds_2d['t2m'].shape)\n",
    "    mask[lat_index, lon_index] = 1\n",
    "    mask = mask.astype(bool)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f'DONE masking raster data with arbitrary shape in {end - start} seconds')\n",
    "    print('### ~~~~~~ ###')\n",
    "\n",
    "    # visualize the shape, all pixels and masked pixels\n",
    "    m = gdf_shape.explore(name='shape', tiles='Stamen Terrain')\n",
    "    gdf_2d.explore(m=m, column='t2m', name='api_request_points', cmap='Oranges')\n",
    "    gdf_masked.explore(m=m, column='t2m', name='masked_points', cmap='Blues')\n",
    "    folium.LayerControl().add_to(m)\n",
    "    # m.save('poc_a_map.html')\n",
    "    return mask, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function: aggregate in arbitrary shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "\n",
    "def agg_in_shape(shape):\n",
    "    # request the ERA5 API\n",
    "    fpath = request_era5_api('poc_b.nc', shape)\n",
    "\n",
    "    # mask the raster data with arbitrary shape\n",
    "    mask, m = shape_mask(fpath, shape)\n",
    "\n",
    "    # open the file\n",
    "    ds = nc.Dataset(fpath)\n",
    "\n",
    "    # read the temperature raster\n",
    "    all_temperature = ds['t2m'][:]\n",
    "    print('\\nBEFORE masking')\n",
    "    print(f'shape: {all_temperature.shape}')\n",
    "    print(f'count of pixels: {all_temperature.count()}')\n",
    "    print(f'min: {all_temperature.min()}')\n",
    "    print(f'max: {all_temperature.max()}')\n",
    "    print(f'mean: {all_temperature.mean()}')\n",
    "    print(f'std: {all_temperature.std()}')\n",
    "\n",
    "    # mask the raster data\n",
    "    all_temperature.mask = ~mask\n",
    "    print('\\nAFTER masking')\n",
    "    print(f'shape: {all_temperature.shape}')\n",
    "    print(f'count of pixels: {all_temperature.count()}')\n",
    "    print(f'min: {all_temperature.min()}')\n",
    "    print(f'max: {all_temperature.max()}')\n",
    "    print(f'mean: {all_temperature.mean()}')\n",
    "    print(f'std: {all_temperature.std()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### ~~~~~~ ###\n",
      "START requesting ERA5 API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 14:23:01,319 INFO Welcome to the CDS\n",
      "2023-07-11 14:23:01,320 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2023-07-11 14:23:01,588 INFO Request is completed\n",
      "2023-07-11 14:23:01,589 INFO Downloading https://download-0003-clone.copernicus-climate.eu/cache-compute-0003/cache/data6/adaptor.mars.internal-1689093330.3342187-10333-14-e3f17986-ec9e-42c7-a296-b89ca9e8264c.nc to data/download/poc_b.nc (1.1M)\n",
      "2023-07-11 14:23:03,164 INFO Download rate 698.9K/s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE requesting ERA5 API in 3.218372106552124 seconds\n",
      "### ~~~~~~ ###\n",
      "\n",
      "\n",
      "### ~~~~~~ ###\n",
      "START masking raster data with arbitrary shape\n",
      "shape of the whole raster data: (24, 96, 244)\n",
      "shape of the sliced raster data: (96, 244)\n",
      "DONE masking raster data with arbitrary shape in 0.18700170516967773 seconds\n",
      "### ~~~~~~ ###\n",
      "\n",
      "BEFORE masking\n",
      "shape: (24, 96, 244)\n",
      "count of pixels: 562176\n",
      "min: 228.93496704101562\n",
      "max: 281.08119201660156\n",
      "mean: 252.67160863433028\n",
      "std: 13.578592449175936\n",
      "\n",
      "AFTER masking\n",
      "shape: (24, 96, 244)\n",
      "count of pixels: 244728\n",
      "min: 228.93496704101562\n",
      "max: 274.79735427634546\n",
      "mean: 242.42570170121715\n",
      "std: 8.410893044220265\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file('data/vector/greenland_main_island.geojson')  # read the shape from a geojson file\n",
    "shape = gdf.loc[0, 'geometry']  # get an object of an arbitrary shape\n",
    "\n",
    "agg_in_shape(shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
